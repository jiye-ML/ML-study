Stacking的想法比bagging更为简单，曾经有人把boosting叫做串行集成方法，bagging叫做并行的集成方法，事实上stacking也是串行的集成。所谓stack，就像程序中的调用栈，堆叠起来层层调用。

![image-20190320100630158](/Volumes/jiye-学习/AI/ML-study/readme/08.stacking-图示.png)

首先我们会像bagging方法一样，训练出不同的基学习器，然后并不直接对这些基学习器的输出做加权平均，而是将上一步基学习器应用到数据上，将数据的输出作为下一层学习器的输入。从某种意义上，上一层的学习器是一个新数据的生成器，将原有的数据映射到另一个特征空间，也可以看成是上一层的学习器是对样本做了特征提取。



比如，对数据利用朴素贝叶斯的办法，朴素贝叶斯模型会输出样本属于不同类别的后验概率，有n个类别，就会产生n个后验概率，然后将上一层的该样本的后验概率作为数据的特征，target保持不变，作为新数据，放入下一层的学习器。

