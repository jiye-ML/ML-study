1、不需要很多样本，不需要有很多样本并不意味着训练样本的绝对量很少，而是说相对于其他训练分类算法比起来，同样的问题复杂度下，
SVM需求的样本相对是较少的。并且由于SVM引入了核函数，所以对于高维的样本，SVM也能轻松应对。
2、结构风险最小。这种风险是指分类器对问题真实模型的逼近与问题真实解之间的累积误差。
3、非线性，是指SVM擅长应付样本数据线性不可分的情况，主要通过松弛变量（也叫惩罚变量）和核函数技术来实现，这一部分也正是SVM的精髓所在。
