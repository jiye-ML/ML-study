### 精准，召回和 F-measures

直观地来理解，[precision](https://en.wikipedia.org/wiki/Precision_and_recall#Precision) 是 the ability of the classifier not to label as positive a sample that is negative （classifier （分类器）的标签不能被标记为正的样本为负的能力），并且 [recall](https://en.wikipedia.org/wiki/Precision_and_recall#Recall) 是 classifier （分类器）查找所有 positive samples （正样本）的能力。

[F-measure](https://en.wikipedia.org/wiki/F1_score) (![F_\beta](https://sklearn.apachecn.org/docs/0.21.3/img/5bd6037aeb804486a6f7cc0415ace8fc.jpg) 和 ![F_1](https://sklearn.apachecn.org/docs/0.21.3/img/a51f44dfa9b1942326c669c5ffe3f9f6.jpg) measures) 可以解释为 precision （精度）和 recall （召回）的 weighted harmonic mean （加权调和平均值）。 ![F_\beta](https://sklearn.apachecn.org/docs/0.21.3/img/5bd6037aeb804486a6f7cc0415ace8fc.jpg) measure 值达到其最佳值 1 ，其最差分数为 0 。与 ![\beta = 1](https://sklearn.apachecn.org/docs/0.21.3/img/7ca5945518e2f3eff72bd67b029e919a.jpg), ![F_\beta](https://sklearn.apachecn.org/docs/0.21.3/img/5bd6037aeb804486a6f7cc0415ace8fc.jpg) 和 ![F_1](https://sklearn.apachecn.org/docs/0.21.3/img/a51f44dfa9b1942326c669c5ffe3f9f6.jpg) 是等价的， recall （召回）和 precision （精度）同样重要。

[`precision_recall_curve`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve) 通过改变 decision threshold （决策阈值）从 ground truth label （被标记的真实数据标签） 和 score given by the classifier （分类器给出的分数）计算 precision-recall curve （精确召回曲线）。

[`average_precision_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score) 函数根据 prediction scores （预测分数）计算出 average precision (AP)（平均精度）。该分数对应于 precision-recall curve （精确召回曲线）下的面积。该值在 0 和 1 之间，并且越高越好。通过 random predictions （随机预测）， AP 是 fraction of positive samples （正样本的分数）。

![\text{AP} = \sum_n (R_n - R_{n-1}) P_n](https://sklearn.apachecn.org/docs/0.21.3/img/score007.png)

其中Pn和Rn是第n个阈值处的precision和recall。对于随机预测，AP是正样本的比例。

参考文献 [Manning2008] 和 [Everingham2010] 提出了AP的两种可替代变体对precision-recall曲线进行内插。 当前，函数`average_precision_score`还没有实现任何具备内插的变体版本。 参考文献 [Davis2006] 和 [Flach2015] 描述了为什么precision-recall曲线上的点的线性内插提供了一个过于乐观(overly-optimistic)的分类器性能度量。 在函数`auc`中使用梯形规则(trapezoidal rule)计算曲线下面积的时候，这个线性内插(linear interpolation)会被使用。

几个函数可以让您实现 analyze the precision （分析精度），recall（召回） 和 F-measures 得分:

| 调用                                                         | 功能                                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| [`average_precision_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score)(y_true, y_score[, …]) | Compute average precision (AP) from prediction scores        |
| [`f1_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score)(y_true, y_pred[, labels, …]) | Compute the F1 score, also known as balanced F-score or F-measure |
| [`fbeta_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.fbeta_score.html#sklearn.metrics.fbeta_score)(y_true, y_pred, beta[, labels, …]) | Compute the F-beta score                                     |
| [`precision_recall_curve`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve)(y_true, probas_pred) | Compute precision-recall pairs for different probability thresholds |
| [`precision_recall_fscore_support`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html#sklearn.metrics.precision_recall_fscore_support)(y_true, y_pred) | Compute precision, recall, F-measure and support for each class |
| [`precision_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score)(y_true, y_pred[, labels, …]) | Compute the precision                                        |
| [`recall_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score)(y_true, y_pred[, labels, …]) | Compute the recall                                           |

请注意，[`precision_recall_curve`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve) 函数仅限于 binary case （二分情况）。 [`average_precision_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score) 函数只适用于 binary classification and multilabel indicator format （二分类和多标签指示器格式）。

> **示例**:
>
> - 参阅 [Classification of text documents using sparse features](https://scikit-learn.org/stable/auto_examples/text/document_classification_20newsgroups.html#sphx-glr-auto-examples-text-document-classification-20newsgroups-py) 例如 [`f1_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score) 用于分类文本文档的用法。
> - 参阅 [Parameter estimation using grid search with cross-validation](https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py) 例如 [`precision_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score) 和 [`recall_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score) 用于 using grid search with nested cross-validation （使用嵌套交叉验证的网格搜索）来估计参数。
> - 参阅 [Precision-Recall](https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html#sphx-glr-auto-examples-model-selection-plot-precision-recall-py) 例如 [`precision_recall_curve`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve) 用于 evaluate classifier output quality（评估分类器输出质量）。
>
> **参考资料**
>
> - [Manning2008] C.D. Manning, P. Raghavan, H. Schütze, [Introduction to Information Retrieval](https://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-ranked-retrieval-results-1.html), 2008.
> - [Everingham2010] M. Everingham, L. Van Gool, C.K.I. Williams, J. Winn, A. Zisserman, [The Pascal Visual Object Classes (VOC) Challenge](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.157.5766&rep=rep1&type=pdf), IJCV 2010.
> - [Davis2006] J. Davis, M. Goadrich, [The Relationship Between Precision-Recall and ROC Curves](http://www.machinelearning.org/proceedings/icml2006/030_The_Relationship_Bet.pdf), ICML 2006.
> - [Flach2015] P.A. Flach, M. Kull, [Precision-Recall-Gain Curves: PR Analysis Done Right](https://papers.nips.cc/paper/5867-precision-recall-gain-curves-pr-analysis-done-right.pdf), NIPS 2015.