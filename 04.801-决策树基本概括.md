
根据[sklearn官网 - 1.10.Decision Trees](http://scikit-learn.org/stable/modules/tree.html)总结如下：

1. 优势（Advantages）：
  - 易理解，解释性好，易可视化；
  - 数据预处理少；
  - 复杂度O(logN)；
  - 支持多输出；
  - 白盒模型，布尔逻辑；
  - 模型好坏易验证；
  - 容忍先验知识错；

2. 劣势（Disadvantages）：
  - 决策树生成易太大、**过拟合**；（需要**剪枝**、设置树**最大深度**等后续操作。）
  - 模型生成**不稳定**，易受小错误样本影响；
  - 学习最优模型是**N-P难题**，贪心搜索易陷入**局部最优**；（可采用随机初始化生成多个模型。）
  - 不支持非线性逻辑，如**XOR**；
  - **数据不平衡**时生成的树形差；   

3. 使用数据类型：
    * 支持标称变量+连续变量；
* 划分数据集的大原则是：将无序的数据变得更加有序；
* 信息熵 & 信息增益
    * 熵： 熵（entropy）指的是体系的混乱的程度，在不同的学科中也有引申出的更为具体的定义，是各领域十分重要的参量。
    * 信息熵（香农熵）： 是一种信息的度量方式，表示信息的混乱程度，也就是说：信息越有序，信息熵越低。
    例如：火柴有序放在火柴盒里，熵值很低，相反，熵值很高。
    ![信息熵计算公式](readme/信息熵计算公式_01.png)
    * 信息增益： 在划分数据集前后信息发生的变化称为信息增益。
	
* 决策树的一般流程：
    * 收集数据：可以使用任何方法。
    * 准备数据：树构造算法只适用于标称型数据，因此数值型数据必须离散化。
    * 分析数据：可以使用任何方法，构造树完成之后，我们应该检查图形是否符合预期。
    * 训练算法：构造树的数据结构。
    * 测试算法：使用经验树计算错误率。（经验树没有搜索到较好的资料，有兴趣的同学可以来补充）
    * 使用算法：此步骤可以适用于任何监督学习算法，而使用决策树可以更好地理解数据的内在含义。
