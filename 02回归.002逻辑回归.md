* [【机器学习笔记1】Logistic回归总结](https://blog.csdn.net/achuo/article/details/51160101)
  * 基本原理
      1. 找一个合适的预测函数，一般表示为h函数，该函数就是我们需要找的分类函数，它用来预测输入数据的判断结果。
      2. 构造一个Cost函数，该函数表示预测的输出（h）与训练数据类别（y）之间的偏差，将Cost求和或者求平均，记为J(θ)函数，表示所有训练数据预测值与实际类别的偏差。
      3. J(θ)函数的值越小表示预测函数越准确，所以这一步需要做的是找到J(θ)函数的最小值。找函数的最小值有不同的方法，Logistic Regression实现时有的是梯度下降法（Gradient Descent）。
  * s的取值是[−∞,+∞]的值，但是我们想要的是一个[0,1]之间的值。因此需要一个转换函数来把这个分数转换成[0,1]之间的值。这个函数称为Logistic 函数，Logistic函数是一个S形的函数。 
  * 先把问题归为极大似然问题，然后利用梯度下降求解；